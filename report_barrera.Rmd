---
title: "Replication of Barrera-Osorio et al 2011"
author: "Dimitrios Papdoupoulos & Eva-Maria Bonin"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
    number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
    number_sections: yes
---

\newpage


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# packages -> double check that all these are needed.


library(knitrBootstrap)
library(dplyr)
library(haven)
library(table1)
library(lmtest)
library(ggplot2)
library(sandwich)
library(tidyverse)
library(broom)
library(car)
library(modelsummary)
library(fixest)
library(kableExtra)
library(gridExtra)
library(clusterSEs)



```



# Motivation


## Why is this research question relevant?

Education in Colombia and other middle-income countries face challenges such as high dropout rates among low-income students, and the reasons behind them, such as the high cost of education. Conditional cash transfers (CCTs) are an evidence-based intervention to increase participation in education. However, the authors highlight that there is little variability in the structure of programmes. The paper investigates if changes in the timing of payments affect the outcomes of interest: Attendance and re-enrollment. Optimising the structure of CCTs may contribute to improved education outcomes and reduce disparities in access to education.

## What are the main hypotheses?

* Null hypothesis 1: $$ \beta_{B} Basic - \beta_{S} Savings = 0 $$ 
* Alternative hypothesis 1: The savings model will improve outcomes compared to the basic programme by relaxing possible savings constraints.

There are additional hypotheses that are not relevant to our replication:

* Alternative hypothesis 2: The "Tertiary" intervention will improve rates of graduation and tertiary enrollment compared to the basic programme by providing direct incentives for continuation of education. Null: The Tertiary intervention does not produce better outcomes than the control condition.
* Alternative hypothesis 3: Any of the three treatments leads to better outcomes than no intervention. Null: Neither intervention produces better outcomes than the control condition.


# Data sources

We investigated performing the replication with the data provided as part of the lecture. However, we soon discovered that the file did not contain all required variables, nor was there any meta data or other information about the variables in the dataset. A brief search revealed that the data and STATA scripts used to obtain the authors' results are [freely available here](https://www.openicpsr.org/openicpsr/project/113783/version/V1/view?path=/openicpsr/113783/fcr:versions/V1/AEJApp_2010-0132_Data&type=folder).

For this project, we reference the following files:

* Data file: Public_Data_AEJApp_2010-0132.dta
* STATA script for Table 3: Table_03_Attendance.do
* Meta data: AEJApp_2010-0132_Data_ReadMe.pdf


## Where does the data come from (country, time period, source)?
Data were collected in San Christobal ("Basic" and "Savings" experiments) and in Suba ("Tertiary" experiment) and combined from six different sources:

* SISBEN surveys 2003 and 2004: Baseline data on eligible families
* Programme registration data: Basic information on students
* Administrative records: Enrollment records
* Direct observation in 68 out of 251 schools: Attendance data in last quarter of 2005 for 7,158 students.
* Survey in 68 schools: Baseline data collection in 2005. 
* Survey in 68 schools: Follow-up in 2006.

## What are the key variables and how are these measured?
Key variables for the replication of Table 3 are the outcome variable, *at_msamean*. This measures the percentage of days absent using a verified attendance measure (see metadata doc) and takes values between 0 and 1 (scale). Another important variable is the clustering variable, *school_code*, which has 234 levels (one expression of the variable for each school in the sample). The treatment indicators, *T1_treat*, *T2_treat*, *T3_treat*, are binary variables indicating whether the participant was part of that intervention (value = 1) or not (value = 0).

Additionally, there is a large number of demographic variables at the individual and household level, measured either as scale variables or categorical variables. Details can be found [here](./AEJApp_2010-0132_Data_ReadMe.pdf). 

\newpage

# Method

## Research design
The research paper describes three interventions designed to improve attendance and educational outcomes for students in Colombia.

The first intervention ("basic") is similar to the PROGRESA/OPORTUNIDADES program, a conditional cash transfer program in Mexico that operated from 1997 to 2012. It pays participants 30,000 pesos per month (approximately USD 15) if the child attends at least 80% of the days in that month. Payments are made bi-monthly through a dedicated debit card, and students will be removed from the program if they fail to meet attendance targets or are expelled from school.

The second intervention, called the savings treatment, pays two-thirds of the monthly amount (20,000 pesos or USD 10) to students' families on a bi-monthly basis, while the remaining one-third is held in a bank account. The accumulated funds are then made available to students' families during the period in which students prepare to enroll for the next school year, with 100,000 pesos (US$50) available to them in December if they reach the attendance target every month.

The third intervention, called the tertiary treatment, incentivizes students to graduate and matriculate to a higher education institution. The monthly transfer for good attendance is reduced from 30,000 pesos per month to 20,000 pesos, but upon graduating, the student earns the right to receive a transfer of 600,000 pesos (USD 300) if they enroll in a tertiary institution, and after a year if they fail to enroll upon graduation.

Students were removed from the program if they fail to meet attendance targets, fail to matriculate to the next grade twice, or are expelled from school.

In our replication, we focus on the first and second intervention.

The eligibility criteria for the "basic" and "savings" experiments were as follows:

* Children had to have finished grade 5 and be enrolled in grades 6 - 10.
* The children's families had to be classified into the bottom two categories on Colombia's poverty index (SISBEN).
* Only households living in San Cristobal prior to 2004 were eligible to participate.

The paper investigates differences in enrollment and graduation / progression to tertiary education for the three treatment groups compared to untreated controls. Randomization to treatment vs control group was stratified by location, school public vs private, gender and grade.


## Data preparation

We imported the data file from STATA format and prepared it for analysis by first turning categorical variables into factors. For convenience when producing graphs, we combined the three treatment indicators into a single factor variable with four expressions (0 = control group, 1 = T1, 2 = T2, 3 = T3).

We then translated the STATA commands to filter the data in line with the inclusion criteria:

* Dropping ineligible cases from Suba: Drop if suba == 1 
* Keeping only those who were selected for the survey in schools: survey_selected == 1
* Drop if grade is < 6 or grade is 11



```{r data_prep}

# Importing STATA file

barrera <- read_dta("data/Public_Data_AEJApp_2010-0132.dta")

# Turning variables into factor variables

barrera$f_teneviv <- factor(barrera$s_teneviv, levels = c(1, 2, 3, 4), labels = c("Rented", "Mortgaged", "Owned outright", "Other"))
barrera$f_estcivil <- factor(barrera$s_estcivil, levels = c(1, 2, 3, 4, 5), labels = c("Free union", "Married", "Widow(er)", "Divorced", "Single"))
barrera$f_estrato <- factor(barrera$s_estrato, levels = c(0, 1, 2), labels = c("Class 0", "Class 1", "Class 2"))
barrera$f_grade <- factor(barrera$grade)
barrera$f_sexo <- factor(barrera$s_sexo, levels = c(0,1), labels = c("Female", "Male"))
barrera$f_single <- factor(barrera$s_single, levels = c(0,1), labels = c("No", "Yes"))
barrera$f_over_age <- factor(barrera$s_over_age, levels = c(0,1), labels = c("No", "Yes"))
barrera$f_suba <- factor(barrera$suba, levels = c(0,1), labels = c("San Cristobal", "Suba"))


# Labelling variables

label(barrera$f_teneviv) <- "House posession"
label(barrera$f_estcivil) <- "Marital status of head of household"
label(barrera$f_estrato) <- "Estrato classification"
label(barrera$f_grade) <- "Grade"
label(barrera$f_sexo) <- "Gender"
label(barrera$f_single) <- "Single parent household"
label(barrera$f_over_age) <- "Child is older than normal for grade"
label(barrera$f_suba) <- "Municipality"
label(barrera$at_msamean) <- "Attendance (%)"
label(barrera$T1_treat) <- "Basic (T1)"
label(barrera$T2_treat) <- "Savings (T2)"
label(barrera$T3_treat) <- "Tertiary (T3)"
label(barrera$s_utilities) <- "Utilities"			
label(barrera$s_durables)	<- "Index of durable goods"
label(barrera$s_infraest_hh) <- "Physical infrastructure index of house"
label(barrera$s_age_sorteo) <- "Age"



```
``` {r filtered, echo = TRUE}

# Generate one variable to capture treatment assignment (T1, T2, control)

barrera$T1T2T3 <- case_when(
  barrera$T1_treat == 1 ~ 1,
  barrera$T2_treat == 1 ~ 2,
  barrera$T3_treat == 1 ~ 3,
  barrera$T1_treat == 0 & barrera$T2_treat == 0 & barrera$T3_treat == 0 ~ 0
)

barrera$T1T2T3 <- factor(barrera$T1T2T3, level = c(0, 1, 2, 3), labels = c("Control", "Basic (T1)", "Savings (T2)", "Tertiary (T3"))


# Filtering data in line with the following STATA code operations to reproduce table 3, columns 1-3:
# Dropping ineligible cases from Suba: Drop if suba == 1 and grade is < 9
# drop if suba == 1 & grade < 9; 
# The above seems to be a mistake in the STATA code: this should be grade < 6 instead of < 9. 
# Keeping only those who were selected for the survey:
# keep if survey_selected;
# Drop if they are in grade 11
# Filtered data

filtered_barrera <- barrera %>% filter(suba == 0, grade >= 6, survey_selected == 1, grade != 11)


```

The dataset for our analysis is called *filtered_barrera*.



## Analysis

### What are the assumptions of the method?

The authors initially use simple linear regression to compare treatment groups. They model the relationship between a dependent variable (outcome; attendance) and two independent variables (whether participant is allocated to treatment "basic", and whether participant is allocated to treatment "savings".)

The assumptions about the data underlying linear regression are:

1. Linearity: There should be a linear relationship between the independent and dependent variables.

2. Independence: The observations used in the regression analysis should be independent of each other. In other words, the value of one observation should not be influenced by the value of another observation.

3. Homoscedasticity: The variance of the dependent variable should be constant across all values of the independent variable(s).

4. Normality: The dependent variable should be normally distributed at each level of the independent variable(s).

5. No multicollinearity: If there are multiple independent variables in the regression model, there should be no high correlation between these independent variables.

If these assumptions are not met, this can lead to unreliable estimators (regression coefficients) and / or biased standard errors, i.e. standard errors that are systematically smaller or larger than the "true" standard error. This means that the relationship between dependent and independent variables is not estimated correctly by the model.


### Are these assumptions plausible in this example?

We test the assumptions of the simplest regression model using the procedure detailed [here](https://godatadrive.com/blog/basic-guide-to-test-assumptions-of-linear-regression-in-r).


```{r mod0, echo = TRUE}

# Setting up model
mod0 <- lm(data = filtered_barrera, at_msamean ~ T1_treat + T2_treat)
```

```{r, echo = TRUE}
# 1. Linearity and 3. heteroskedasticity
plot(mod0, 1)

```

The plot is not what we would typically expect if these assumptions were fulfilled.

```{r, echo = TRUE}
# 2. Independence
durbinWatsonTest(mod0)
```

A result for the p-value > 0.05 would suggest we can reject the Null hypothesis and the assumption is met.

```{r, echo = TRUE}
# 4. Normality
plot(mod0, 3)
```

This is again not a typical plot.

Plotting fitted vs actual values for T1.

```{r, echo = TRUE}

# Souce: http://www.sthda.com/english/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/

model.diag.mod0 <- augment(mod0)

ggplot(model.diag.mod0, aes(at_msamean, T1_treat)) +
  geom_point() +
  stat_smooth(method = lm, se = FALSE) +
  geom_segment(aes(xend = at_msamean, yend = .fitted), color = "red", linewidth = 0.3)



```

Another atypical plot, but the variance seems the same.

The plots reflect the model set-up, where averages are estimated by treatment group. There appears to be little variation within groups. This is further explored
graphically below.

```{r outcome_var, echo = TRUE}

# Plotting the outcome variable

# A boxplot for each group
ggplot(filtered_barrera, aes(x = T1T2T3, y = at_msamean)) +
  geom_boxplot() +    # Box plot for visualization
  labs(x = "Treatment", y = "Attendance %")  # Label the axes

# Histogram of the outcome variable

hist(filtered_barrera$at_msamean)

# Create separate histograms of at_msamean for each level of T1T2T3

ggplot(filtered_barrera, aes(x = at_msamean)) +
  geom_histogram(binwidth = 0.07, alpha = 0.5, position = "identity") +
  labs(x = "Attendance %", y = "Frequency") +
  facet_wrap(~T1T2T3, ncol = 3) +
  geom_vline(xintercept = 0.8, color = "red", linetype = "dashed")+
  theme(panel.border = element_rect(colour = "black", fill = NA, linewidth = 1),
        panel.spacing = unit(0.5, "lines"))

```

We can see that a large proportion of each sample has an attendance record above the 80% requirement, explaining the skew of the distribution observed in the box plots. It is therefore unlikely that the assumptions underlying the linear model are met (although the normality assumption can be relaxed with sufficiently large samples, which is the case here).



## Model specifications

In addition to the above, one violation that should be expected based on the data is that of independence. It is likely that there are unobserved characteristics at the school level (e.g. school culture and rules) that affect the outcome. The following equations show formally how the analyses were conceptualised(where i is the individual and j is the school). While the authors state that standard errors are clustered also clustered within the individual, the STATA code suggests that the only clustering variable was the school (*school code*), and this is what we have replicated below. 

Model 1:
$$ y_{ij} = \beta_0 + \beta_{B} Basic_i + \beta_{S} Savings_i + \epsilon_{ij} $$ 
Model 1 is a simple linear model with only treatment allocation as the dependent variable, while model 2 also includes a collection of student and household characteristics.

Model 2: 
$$ y_{ij} = \beta_0 + \beta_{B} Basic_i + \beta_{S} Savings_i + \delta X_{ijk} + \theta_{j} + \epsilon_{ij} $$ 


Model 3 builds on model two, but includes a fixed effect for the school level. Fixed effect models are used to control for unobserved factors that affect the outcome variable. In this case, the school was chosen as the fixed effect.


\newpage


# Results

## Replication Table 1

We do not replicate Table 1 as published. Instead, we show the same information for the sample in our replication (n=5,799). Note that several factor variables were treated as continuous in the original paper, and we have corrected this here, showing proportions instead.


```{r}

# Table 1


# Using n = 5,799 to get the sample actually used in our model (for columns 1-3). Variables selected based on Table 1.
# Note: Some factor variables are presented in the paper as scale vars.

# House posessions - f_teneviv
# utilities - s_utilities
# durable goods - s_durables
# physical infrastructure - s_infraest_hh
# age - s_age_sorteo
# gender - s_sexo
# years of education - s_yrs
# single head - s_single
# Age of head - s_edadhead
# years of ed head - s_yrshead
# people in household - s_tpersona
# Member under 18 - s_num18
# estrato - f_estrato
# SISBEN - s_puntaje
# household income - s_ingtotal
```

```{r table1, echo = TRUE}

table1 <- table1(~ f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + f_sexo + s_yrs + f_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal | ~ factor(T1T2T3), data=filtered_barrera)

table1

```



## Replication of Table 3

We replicate Table 3, columns 1-3 using the "feols()" function which allows us to specify linear models with fixed effects and clustered standard errors. We test the Null hypothesis $$ \beta_{B} Basic - \beta_{S} Savings = 0 $$. 

```{r models, echo = TRUE}

# Model 1

# Source https://evalf21.classes.andrewheiss.com/example/standard-errors/

feols_m1 <- feols(data = filtered_barrera,
               at_msamean ~ T1_treat + T2_treat,
               cluster = ~ school_code)

# Model 2

feols_m2 <- feols(data = filtered_barrera, 
                  at_msamean ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age,
                  cluster = ~ school_code)

# Model 3
feols_m3 <- feols(data = filtered_barrera, 
                  at_msamean ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age | school_code,
                  cluster = ~ school_code)

# Specify hypothesis tests

hyp1 <- linearHypothesis(feols_m1, "T1_treat - T2_treat = 0")
hyp2 <- linearHypothesis(feols_m2, "T1_treat - T2_treat")
hyp3 <- linearHypothesis(feols_m3, "T1_treat - T2_treat")

# Save results and format separately from coefficients.
chi1 <- format(round(hyp1[,2][2], 2), nsmall = 2)
chi2 <- format(round(hyp2[,2][2], 2), nsmall = 2)
chi3 <- format(round(hyp3[,2][2], 2), nsmall = 2)
p1 <- format(round(hyp1[,3][2], 2), nsmall = 2)
p2 <- format(round(hyp2[,3][2], 2), nsmall = 2)
p3 <- format(round(hyp3[,3][2], 2), nsmall = 2)

# Defining additional rows for the table output

rows <- tribble(~term, ~"(1)", ~"(2)", ~"(3)",
                "Chi-squared", chi1, chi2, chi3,
                "p-value", p1, p2, p3)
attr(rows, "position") <- c(5,6)



# Combining all model outputs into one table and showing only coefficients on T1_treat and T2_treat.
# Adding grouping label to hypothesis test results and grouped column header, also footnotes.

table3 <- modelsummary(list(feols_m1, feols_m2, feols_m3) %>%
               setNames(c("Model 1", "Model 2", "Model 3")),
             coef_omit = -c(2,3),
             gof_omit = "AIC|BIC|RMSE|R2 W|R2 A",
             stars = TRUE,
             add_rows = rows,
             coef_rename = c("Basic treatment","Savings treatment"),
             title = "Table 3 - Effects on Monitored School Attendance Rates",
             ) |>
             kable_styling(bootstrap_options = "basic") |> pack_rows(index = c("Model resuls" = 4, "Basic - Savings = 0" = 2, "Test" = 4)) |>
                                                        add_header_above(c(" " = 1, "Basic - Savings" = 3)) |>
                                                                           footnote(general = "We've created a footnote.",
                                                                                    number = c("Footnote 1", "Footnote 2"))
table3

```

Our models replicate Table 3 in terms of model coefficients, p-values, standard errors and R-squared. 



## Replication of Figure 1

We replicated Figure 1 because there was no code available for this from the repository. However, the description of the method in the paper was not sufficient to arrive at the same figure, as the authors applied "local polynomial regressions (bandwith = 0.075)". We use a linear model to approximate their results.



``` {r plot, echo = TRUE}

#plot

barrera$T1T2T3 <- case_when(
  barrera$T1_treat == 1 ~ 1,
  barrera$T2_treat == 1 ~ 2,
  barrera$T3_treat == 1 ~ 3,
  barrera$T1_treat == 0 & barrera$T2_treat == 0 & barrera$T3_treat == 0 ~ 0
)


plot <- ggplot(data=filtered_barrera, aes(x=at_baseline, y=at_msamean, color=factor(T1T2T3))) +
  geom_smooth(method="lm", se=FALSE)+
  xlim(0.65, 0.9)+
  scale_color_discrete(name = "Treatments", labels = c("Control", "Basics", "Savings"))+
  labs(y = "Actual Attendance ", x = "Predicted Baseline Attendance")


plot +  ggtitle("Monitored Attendance by Predicted Attendance Basic-Savings Experiment")


```


## Exploratory analysis: Logistic regression

Part of the problem with this model is the outcome variable, which has a ceiling effect - values cannot exceed 100\%, and many people have high attendance, with target attendance also being high at 80%.


It may be worthwhile investigating whether there is a significant difference in the proportion above the cut-off between samples.

```{r expl1}

# Create separate cumulative distribution plots of at_msamean for each level of T1T2T3

ggplot(filtered_barrera, aes(x = at_msamean)) +
  stat_ecdf(aes(color = T1T2T3)) +
  labs(x = "at_msamean", y = "Cumulative Probability") +
  facet_wrap(~T1T2T3, ncol = 3) +
  geom_vline(xintercept = 0.8, color = "red", linetype = "dashed") +
  theme(panel.border = element_rect(colour = "black", fill = NA, linewidth = 1),
        panel.spacing = unit(0.5, "lines"))


```

What proportion in each group falls at or above the target of 80% attendance?


```{r expl2}

cutoff <- 0.8  # set the cutoff value

filtered_barrera %>% 
  group_by(T1T2T3) %>% 
  summarize(prop_cutoff = round(sum(at_msamean >= cutoff),2) / n())



```

Variability in the outcome variable is limited because most students attend at least 80% of the time. An alternative model specification may be to analyse differences in proportion of attendance (above / below cut-off).To this end, a binary variable called *above_cutoff* was created and a model based on model 3 (but without clustered standard errors) was run using the glm command.




```{r glm, echo = TRUE}

# Calculating new column: is participant at or above cut-off?


filtered_barrera <- filtered_barrera %>% 
  mutate(above_cutoff = ifelse(at_msamean >= cutoff, 1, 0))

# Running above model but with this as outcome --> note that the residual plots don't pick up the clustered standard errors.

mod_bi <- glm(data = filtered_barrera, above_cutoff ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age + factor(school_code), family = binomial())

# vcov1 <- vcovCL(mod_bi, cluster = filtered_barrera$school_code)
# coeftest(mod_bi, vcov = vcov1)


# To compare, running linear model as glm:

mod_gau <- glm(data = filtered_barrera, at_msamean ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age + factor(school_code), family = gaussian())

# vcov2 <- vcovCL(mod_gau, cluster = filtered_barrera$school_code)
# coeftest(mod_gau, vcov = vcov2)

```

Comparing the coefficients and the Akaike criterion for the two models and the previously fitted models using "feols()" shows that the AIC is much larger for the logistic regression, indicating a better model fit. However, the p-values on the treatment coefficients are less convincing, suggesting that with this better fit, the results would not hold at the 95% level of confindence (but at the 90% level, which is more accepted in economics / policy evaluation than other areas of research).


```{r}

# Model outputs

bi_gau <- modelsummary(list(mod_bi, mod_gau, feols_m1, feols_m2, feols_m3) %>%
                         setNames(c("GLM binomial", "GLM Gaussian", "Model 1", "Model 2", "Model 3")),
                       coef_omit = -c(2, 3),
                       gof_map = "aic",
                       stars = TRUE,
                       coef_rename = c("Basic treatment","Savings treatment"),
                       title = "Comparison of logistic and linear regressions (no clustered standard errors)")
bi_gau

```

How do the two GLM models perform in terms of the distribution of residuals?


```{r}


# Fitted values vs actual values

fitted_bi <- augment(mod_bi, data = filtered_barrera, se_fit = TRUE)
fitted_gau <- augment(mod_gau, data = filtered_barrera, se_fit = TRUE)

plot_bi <- ggplot(fitted_bi, aes(x = .resid)) +
  geom_histogram(binwidth = 0.01, color = "white", boundary = 50000)
plot_bi <- plot_bi + ggtitle("GLM binomial")

# plot_bi

plot_gau <- ggplot(fitted_gau, aes(x = .resid)) +
  geom_histogram(binwidth = 0.01, color = "white", boundary = 50000)
plot_gau <- plot_gau + ggtitle("GLM Gaussian")
# plot_gau


# arrange plots side by side

grid.arrange(plot_bi, plot_gau, nrow = 2)

```

The residuals for the logistic regression appear to be slightly more "normal", but this is still not a very good fit.


## Exploratory analysis: A more parsimonious model

Another approach may be to try and fit a more parsimonious model to avoid the risk of colininearity. Many of the covariates appear to be related to poverty. We therefore test if the explanatory power of the model is decreased by removing the variables from Model 3 that may be related to socio-economic status (*f_estrato*), and those that appear related to both poverty and home ownership (utilities, infrastructure, durable goods). We also remove marital status of the head of household, as this is captured in the variable indicating whether the household is headed by a single parent or not. We then compare this model to Model 3, and the logistic regression. 

``` {r parsimony1, echo = TRUE}

# Model 3 but removing income, SISBEN score, utilities, durables, infrastructure, durable goods, and civil status of head of household.
feols_p <- feols(data = filtered_barrera, 
                  at_msamean ~ T1_treat + T2_treat + f_teneviv + s_age_sorteo2 + s_years_back + s_sexo + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato +  f_grade + suba + s_over_age | school_code,
                  cluster = ~ school_code)

``` 

``` {r parsimony2}

# Model outputs

parsy <- modelsummary(list(mod_bi, feols_m3, feols_p) %>%
                         setNames(c("GLM binomial", "Model 3", "Reduced Model 3")),
                       coef_omit = -c(2, 3),
                       gof_map = c("aic","r.squared"),
                       stars = TRUE,
                       coef_rename = c("Basic treatment","Savings treatment"),
                       title = "Comparison of logistic and linear regressions (no clustered standard errors)")
parsy


```

We can see that we really don't lose anything in terms of explanatory power by removing these variables, with R-squared going from 0.089 to 0.085.


\newpage

# Conclusion

We were able to replicate the model coefficients, p-values, standard errors and R-squared, despite the fact that R does not have the same convenient standard options for analysis of clustered data that we find in STATA.

We observe that there are several errors in the STATA code provided by the authors.

Further, none of the models (Model 1, Model 2, Model 3) explain more than 10% of the variation in the data - depspite the inclusion of a large number of co-variates and taking into account potential clustering. It should be noted that there was no attempt by the authors to optimise model fit / adhering to the principle of parsimony by removing those variables that are shown not to improve the model.

Our exploratory analysis using logistic regression shows that one issue may be with the functional form of the model, related to the distribution of the outcome variable. Our parsimonious model indicates that, in fact, many variables included in the original models do not add explanatory power.

Overall, it seems that the analysis could benefit from more thorough consideration of model choice and model fit, with justifications provided for the inclusion of each variable. The evidence generated appears weak due to small values of R-squared and the structural issues mentioned above.






